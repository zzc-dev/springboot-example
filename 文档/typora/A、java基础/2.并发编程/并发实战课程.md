《java并发编程的艺术》

并发编程领域可以抽象成三个核心问题：**分工、同步和互斥**

从性能角度讲，我们为了提高执行一定计算机任务的效率，所以IO等待的时候不能让cpu闲着，所以我们把任务拆分交替执行，有了分时操作系统，出现了并发，后来cpu多核了又有了并行计算。这里也就是作者说的[分工]。分工以后我们为了进一步提升效率和更加灵活地达到目的，所以我们要对任务进行组织编排，也就是对线程组织编排。于是线程之间需要通信，于是操作系统提供了一些让进程，线程之间通信的方式。也就是作者说的[同步]。但是事物总不是完美的。并发和通信带来了较高的编程复杂度，同时也出现了多线程并发操作共享资源的问题。于是天下大势，分久必合，我们又要将对共享资源的访问串行化。所以我们根据现实世界的做法设计了了锁，信号量等等来补充这套体系。也就是作者所说的[互斥]！

![img](D:\myself\springboot-example\文档\typora\images\juc01.png)

# 一、并发理论基础

## 1.1 并发编程的源头

CPU  和 内存读写  和 I/O设备的速度差异，为了合理利用CPU的高性能，平衡这三者的速度差异：

	1. CPU 增加了缓存，以均衡与内存的速度差异；   **内存和缓存数据的不一致引发可见性问题**
 	2. 操作系统增加了进程、线程，以分时复用 CPU，进而均衡 CPU 与 I/O 设备的速度差异；  **线程切换带来的原子性问题**
 	3. 编译程序优化指令执行次序，使得缓存能够得到更加合理地利用。  **指令执行次序优化带来有序性问题**

### 1.1.1 单例模式下有序性问题

```

public class Singleton {
  static Singleton instance;
  static Singleton getInstance(){
    if (instance == null) {
      synchronized(Singleton.class) {
        if (instance == null)
          instance = new Singleton();
        }
    }
    return instance;
  }
}
```

双重检查机制确保了单例，但可能引发NPE

instance = new Singleton();  指令执行：

1. 堆上分配一块内存M
2. 在内存M上实例化对象
3. 将M地址赋值给instance

经过指令优化后的执行顺序：1 -> 3 -> 2

当线程A执行到3时，对象还没有实例化，此时线程B判断instance不为null，操作instance引发NPE

<img src="D:\myself\springboot-example\文档\typora\images\juc02.png" alt="img" style="zoom:50%;" />

**解决方法是 instance变量使用volatile修饰，禁止重排序**

## 1.2 java内存模型：解决有序性和可见性问题

### 1.2.1 volatile

我们声明一个 volatile 变量 volatile int x = 0，它表达的是：告诉编译器，**对这个变量的读写，不能使用 CPU 缓存，必须从内存中读取或者写入**

### 1.2.2 happen-before原则

> 前面一个操作的结果对后续操作是可见的

1. 程序的顺序性规则

   在同一个线程中，按照程序顺序，前面的操作 Happens-Before 于后续的任意操作

2. volatile变量规则

   对一个volatile变量的写操作，Happens-before于后续对这个变量的读操作

3. 传递性规则

   如果 A Happens-Before B，且 B Happens-Before C，那么 A Happens-Before C

4. 管程中的锁规则

   > 管程是一种通用的同步原语，在 Java 中指的就是 synchronized，synchronized 是 Java 里对管程的实现

   一个锁的解锁 Happens-Before 于后续对这个锁的加锁

5. 线程start()规则

   主线程 A 启动子线程 B 后，子线程 B 能够看到主线程在启动子线程 B 前的操作

6. 线程join()规则

   主线程 A 等待子线程 B 完成（主线程 A 通过调用子线程 B 的 join() 方法实现），当子线程 B 完成后（主线程 A 中 join() 方法返回），主线程能够看到子线程的操作

7. 线程中断规则

   线程t1中断线程t2前对变量的写，对于其他线程得知t2被打断后对变量的读可见

### 1.2.3 final

**final 修饰变量时，初衷是告诉编译器：这个变量生而不变，可以可劲儿优化**

**逸出**

```
final int x;
// 错误的构造函数
public FinalFieldExample() { 
  x = 3;
  y = 4;
  // 此处就是讲this逸出，
  global.obj = this;
}
```

### 1.2.4 JMM如何实现（了解）

主要是通过内存屏障(memory barrier)禁止重排序的，即时编译器根据具体的底层体系架构，将这些内存屏障替换成具体的 CPU 指令。对于编译器而言，内存屏障将限制它所能做的重排序优化。而对于处理器而言，内存屏障将会导致缓存的刷新操作。比如，对于volatile，编译器将在volatile字段的读写操作前后各插入一些内存屏障

## 1.3 互斥锁：解决原子性问题

<img src="D:\myself\springboot-example\文档\typora\images\juc03.png" alt="img" style="zoom:80%;" />

synchronized 修饰的方法或代码块前后自动加上加锁 lock() 和解锁 unlock()

用不同的锁对受保护资源进行精细化管理，能够提升性能。这种锁还有个名字，叫细粒度锁

## 1.4 死锁

> 一组互相竞争资源的线程因互相等待，导致“永久”阻塞的现象。

解决死锁的最好方法就是规避死锁

### 1.4.1 死锁产生条件

1. 互斥：共享资源X和Y只能被一个线程占用；
2. 占有且等待：线程 T1 已经取得共享资源 X，在等待共享资源 Y 的时候，不释放共享资源 X；
3. 不可抢占，其他线程不能强行抢占线程 T1 占有的资源；
4. 循环等待，线程 T1 等待线程 T2 占有的资源，线程 T2 等待线程 T1 占有的资源，就是循环等待

   只有这四种条件都满足才会产生死锁

   破环死锁：

1. 破坏占有且等待：一次性申请所有资源
2. 破坏不可抢占：破坏不可抢占条件看上去很简单，核心是要能够主动释放它占有的资源，这一点 synchronized 是做不到的。原因是 synchronized 申请资源的时候，如果申请不到，线程直接进入阻塞状态了，而线程进入阻塞状态，啥都干不了，也释放不了线程已经占有的资源
3. 破坏循环等待：需要对资源进行排序，然后按序申请资源

## 1.5 等待-通知机制

一个完整的等待 - 通知机制：线程首先获取互斥锁，当线程要求的条件不满足时，释放互斥锁，进入等待状态；当要求的条件满足时，通知等待的线程，重新获取互斥锁。

用 synchronized 实现等待 - 通知机制

wait()、notify()、notifyAll()

尽量使用 notifyAll() 
这二者是有区别的，notify() 是会随机地通知等待队列中的一个线程，而 notifyAll() 会通知等待队列中的所有线程。从感觉上来讲，应该是 notify() 更好一些，因为即便通知所有线程，也只有一个线程能够进入临界区。但那所谓的感觉往往都蕴藏着风险，实际上使用 notify() 也很有风险，它的风险在于可能导致某些线程永远不会被通知到

<img src="D:\myself\springboot-example\文档\typora\images\juc04.png" alt="img" style="zoom:67%;" />

​    wait和sleep区别
1：wait释放资源，sleep不释放资源
2：wait需要被唤醒，sleep不需要
3：wait需要获取到监视器，否则抛异常，sleep不需要
4：wait是object顶级父类的方法，sleep则是Thread的方法

## 1.6 安全性、活跃性以及性能问题

### 1.6.1 安全性问题

> **数据竞争（Data Race）**
> 当多个线程同时访问同一数据，并且至少有一个线程会写这个数据的时候，如果我们不采取防护措施，那么就会导致并发 Bug
>
> **竞态条件**
> 指的是程序的执行结果依赖线程执行的顺序

所以你也可以按照下面这样来理解竞态条件。在并发场景中，程序的执行依赖于某个状态变量，也就是类似于下面这样：

```
if (状态变量 满足 执行条件) {
	执行操作
}
```

当某个线程发现状态变量满足执行条件后，开始执行操作；可是就在这个线程执行操作的时候，其他线程同时修改了状态变量，导致状态变量不满足执行条件了

### 1.6.2 活跃性问题

所谓活跃性问题，指的是某个操作无法执行下去。我们常见的“死锁”就是一种典型的活跃性问题，当然除了死锁外，还有两种情况，分别是**“活锁”和“饥饿”**。

**有时线程虽然没有发生阻塞，但仍然会存在执行不下去的情况，这就是所谓的“活锁”**。可以类比现实世界里的例子，路人甲从左手边出门，路人乙从右手边进门，两人为了不相撞，互相谦让，路人甲让路走右手边，路人乙也让路走左手边，结果是两人又相撞了。这种情况，基本上谦让几次就解决了，因为人会交流啊。可是如果这种情况发生在编程世界了，就有可能会一直没完没了地“谦让”下去，成为没有发生阻塞但依然执行不下去的“活锁”

解决“活锁”的方案很简单，谦让时，尝试等待一个随机的时间就可以了

**所谓“饥饿”指的是线程因无法访问所需资源而无法执行下去的情况**

解决“饥饿”问题的方案很简单，有三种方案：
一是保证资源充足，二是公平地分配资源，三就是避免持有锁的线程长时间执行。
这三个方案中，方案一和方案三的适用场景比较有限，因为很多场景下，资源的稀缺性是没办法解决的，持有锁的线程执行的时间也很难缩短。倒是方案二的适用场景相对来说更多一些

### 1.6.3 性能问题

所以我们要尽量减少串行，那串行对性能的影响是怎么样的呢？假设串行百分比是 5%，我们用多核多线程相比单核单线程能提速多少呢？
![image-20201220101746502](D:\myself\springboot-example\文档\typora\images\juc05.png)

提升性能方案：

一、既然使用锁会带来性能问题，那最好的方案自然就是使用无锁的算法和数据结构了
       例如线程本地存储 (Thread Local Storage, TLS)、写入时复制 (Copy-on-write)、乐观锁等；Java 并发包里面的原子类也是一种无锁的数据结构；Disruptor 则是一个无锁的内存队列，性能都非常好……

二、减少锁持有的时间。互斥锁本质上是将并行的程序串行化，所以要增加并行度，一定要减少持有锁的时间。
      使用细粒度的锁、使用读写锁，也就是读是无锁的，只有写的时候才会互斥。

性能方面的度量指标有很多，我觉得有三个指标非常重要，就是：吞吐量、延迟和并发量。
	吞吐量：指的是单位时间内能处理的请求数量。吞吐量越高，说明性能越好。
	延迟：指的是从发出请求到收到响应的时间。延迟越小，说明性能越好。
	并发量：指的是能同时处理的请求数量，一般来说随着并发量的增加、延迟也会增加。所以延迟这个指标，一般都会是基于并发量来说的。例如并发量是 1000 的时候，延迟是 50 毫秒

## 1.7 管程

**管程，指的是管理共享变量以及对共享变量的操作过程，让他们支持并发**

管程和信号量是等价的，所谓等价指的是用管程能够实现信号量，也能用信号量实现管程

### 1.7.1 MESA模型

在管程的发展史上，先后出现过三种不同的管程模型，分别是：Hasen 模型、Hoare 模型和 MESA 模型。其中，现在广泛应用的是 MESA 模型，并且 Java 管程的实现参考的也是 MESA 模型。所以今天我们重点介绍一下 MESA 模型

管程解决互斥问题的思路很简单，就是将共享变量及其对共享变量的操作统一封装起来。假如我们要实现一个线程安全的阻塞队列，一个最直观的想法就是：将线程不安全的队列封装起来，对外提供线程安全的操作方法，例如入队操作和出队操作

**Hasen** 模型里面，要求 notify() 放在代码的最后，这样 T2 通知完 T1 后，T2 就结束了，然后 T1 再执行，这样就能保证同一时刻只有一个线程执行。

**Hoare** 模型里面，T2 通知完 T1 后，T2 阻塞，T1 马上执行；等 T1 执行完，再唤醒 T2，也能保证同一时刻只有一个线程执行。但是相比 Hasen 模型，T2 多了一次阻塞唤醒操作。

**MESA** 管程里面，T2 通知完 T1 后，T2 还是会接着执行，T1 并不立即执行，仅仅是从条件变量的等待队列进到入口等待队列里面。这样做的好处是 notify() 不用放到代码的最后，T2 也没有多余的阻塞唤醒操作。但是也有个副作用，就是当 T1 再次执行的时候，可能曾经满足的条件，现在已经不满足了，所以需要以循环方式检验条件变量。

**notify() 何时可以使用**
还有一个需要注意的地方，就是 notify() 和 notifyAll() 的使用，前面章节，我曾经介绍过，除非经过深思熟虑，否则尽量使用 notifyAll()。那什么时候可以使用 notify() 呢？需要满足以下三个条件：

1. 所有等待线程拥有相同的等待条件；
2. 所有等待线程被唤醒后，执行相同的操作；
3. 只需要唤醒一个线程

## 1.8 线程的生命周期

1. NEW（初始化状态）
2. RUNNABLE（可运行 / 运行状态）
3. BLOCKED（阻塞状态）
4. WAITING（无时限等待）
5. TIMED_WAITING（有时限等待）
6. TERMINATED（终止状态）

### 1.8.1 RUNNABLE 与 BLOCKED 的状态转换

只有一种场景会触发这种转换，就是线程等待 synchronized 的隐式锁。
而当等待的线程获得 synchronized 隐式锁时，就又会从 BLOCKED 转换到 RUNNABLE 状态。

如果你熟悉操作系统线程的生命周期的话，可能会有个疑问：线程调用阻塞式 API 时，是否会转换到 BLOCKED 状态呢？
在操作系统层面，线程是会转换到休眠状态的，但是在 JVM 层面，Java 线程的状态不会发生变化，也就是说 Java 线程的状态会依然保持 RUNNABLE 状态。JVM 层面并不关心操作系统调度相关的状态，因为在 JVM 看来，等待 CPU 使用权（操作系统层面此时处于可执行状态）与等待 I/O（操作系统层面此时处于休眠状态）没有区别，都是在等待某个资源，所以都归入了 RUNNABLE 状态。

而我们平时所谓的 Java 在调用阻塞式 API 时，线程会阻塞，指的是操作系统线程的状态，并不是 Java 线程的状态

### 1.8.2 RUNNABLE 与 WAITING 的状态转换

1. wait()
2. join()
3. LockSupport.park()

### 1.8.3 RUNNABLE 与 TIMED_WAITING 的状态转换

1. wait(time)
2. sleep(time)
3. join(time)
4. LockSupport.parkNanos(Object blocker, long deadline)
5. LockSupport.parkUntil(long deadline)

这里你会发现 TIMED_WAITING 和 WAITING 状态的区别，仅仅是触发条件多了**超时参数**。

### 1.8.4 从 NEW 到 RUNNABLE 状态

Java 刚创建出来的 Thread 对象就是 NEW 状态

NEW 状态的线程，不会被操作系统调度，因此不会执行。Java 线程要执行，就必须转换到 RUNNABLE 状态。从 NEW 状态转换到 RUNNABLE 状态很简单，只要调用线程对象的 start() 方法就可以了

### 1.8.5 从 RUNNABLE 到 TERMINATED 状态

线程执行完 run() 方法后，会自动转换到 TERMINATED 状态，当然如果执行 run() 方法的时候异常抛出，也会导致线程终止。有时候我们需要强制中断 run() 方法的执行，例如 run() 方法访问一个很慢的网络，我们等不下去了，想终止怎么办呢？Java 的 Thread 类里面倒是有个 stop() 方法，不过已经标记为 @Deprecated，所以不建议使用了。正确的姿势其实是调用 interrupt() 方法

## 1.9 interrupt()

interrupt 方法仅仅是通知线程，线程有机会执行一些后续操作，同时也可以无视这个通知

被interrupt的线程，是通过**异常和主动检测**收到通知的

### 1.9.1 异常

如果线程处于以下三种情况，那么当线程被中断的时候，能自动感知到：

1. 来自 Object 类的 wait()、wait(long)、wait(long, int)，

   来自 Thread 类的 join()、join(long)、join(long, int)、sleep(long)、sleep(long, int)

   > 这几个方法的相同之处是，方法上都有: throws InterruptedException 
   >
   > 如果线程阻塞在这些方法上（我们知道，这些方法会让当前线程阻塞），这个时候如果其他线程对这个线程进行了中断，那么这个线程会从这些方法中立即返回，抛出 InterruptedException 异常，同时重置中断状态为 false。

2. 实现了 InterruptibleChannel 接口的类中的一些 I/O 阻塞操作，如 DatagramChannel 中的 connect 方法和 receive 方法等

   > 如果线程阻塞在这里，中断线程会导致这些方法抛出 ClosedByInterruptException 并重置中断状态。

3. Selector 中的 select 方法，参考下我写的 NIO 的文章

   > 一旦中断，方法立即返回

对于以上 3 种情况是最特殊的，因为他们能自动感知到中断（这里说自动，当然也是基于底层实现），
**并且在做出相应的操作后都会重置中断状态为 false**。

4. 如果线程阻塞在 LockSupport.park(Object obj) 方法，也叫挂起，这个时候的中断也会导致线程唤醒，但是唤醒后不会重置中断状态，所以唤醒后去检测中断状态将是 true。

### 1.9.2 主动检测

如果线程处于runnable状态，并且没有阻塞在某个IO操作上，这时就得依赖线程 A 主动检测中断状态了。如果其他线程调用线程 A 的 interrupt() 方法，那么线程 A 可以通过 isInterrupted() 方法，检测是不是自己被中断了

注意：当线程被中断抛出异常后，会重置中断状态，以下代码是个死循环。改进：

​	在抛出异常中加入 ：  Thread.currentThread().interrupt();

```
Thread th = Thread.currentThread();
while(true) {
  if(th.isInterrupted()) {
    break;
  }
  // 省略业务代码无数
  try {
    Thread.sleep(100);
  }catch (InterruptedException e){
    e.printStackTrace();
  }
}
```

## 1.10 创建多少个线程合适

**降低延迟，提高吞吐量**

要想“降低延迟，提高吞吐量”，对应的方法呢，基本上有两个方向，一个方向是优化算法，另一个方向是将硬件的性能发挥到极致。前者属于算法范畴，后者则是和并发编程息息相关了。那计算机主要有哪些硬件呢？主要是两类：一个是 I/O，一个是 CPU。简言之，在并发编程领域，提升性能本质上就是提升硬件的利用率，再具体点来说，就是**提升 I/O 的利用率和 CPU 的利用率**

公式只是建议，需要根据业务场景和压测后再行判断：**理论加经验加实际场景**

对于 CPU 密集型的计算场景，理论上“线程的数量 =CPU 核数”就是最合适的。不过在工程上，线程的数量一般会设置为“CPU 核数 +1

IO密集型：

最佳线程数 =CPU 核数 * [ 1 +（I/O 耗时 / CPU 耗时）]
                     2 * CPU 的核数 + 1

## 1.11 局部变量为什么是线程安全的？

局部变量存在调用栈里

每个线程都有自己的调用栈

栈溢出原因：
  因为每调用一个方法就会在栈上创建一个栈帧，方法调用结束后就会弹出该栈帧，而栈的大小不是无限的，所以递归调用次数过多的话就会导致栈溢出。而递归调用的特点是每递归一次，就要创建一个新的栈帧，而且还要保留之前的环境（栈帧），直到遇到结束条件。所以递归调用一定要明确好结束条件，不要出现死循环，而且要避免栈太深。
解决方法：
\1. 简单粗暴，不要使用递归，使用循环替代。缺点：代码逻辑不够清晰；
\2. 限制递归次数；
\3. 使用尾递归，尾递归是指在方法返回时只调用自己本身，且不能包含表达式。编译器或解释器会把尾递归做优化，使递归方法不论调用多少次，都只占用一个栈帧，所以不会出现栈溢出。然鹅，Java没有尾递归优化。





























