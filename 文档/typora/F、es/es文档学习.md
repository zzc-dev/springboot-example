https://www.elastic.co/guide/cn/elasticsearch/guide/current/_an-empty-cluster.html  es2.x官方中文文档

1. es可以从集群中的任何节点获取数据

2. 批量索引文档，减少网络IO。最佳批处理大小取决于：文档大小和复杂性、集群资源的可用性。
   建议：1000-5000个文档，有效负载5M-10M

3. es的分片故障处理：主分片所在节点故障如何处理

4. es的节点分类

   



响应体：

- `took` – Elasticsearch运行查询多长时间（以毫秒为单位）
- `timed_out` –搜索请求是否超时
- `_shards` –搜索了多少个分片，以及成功，失败或跳过了多少个分片。
- `max_score` –找到的最相关文件的分数
- `hits.total.value` -找到了多少个匹配的文档
- `hits.sort` -文档的排序位置（不按相关性得分排序时）
- `hits._score`-文档的相关性得分（使用时不适用`match_all`）



match：分词查询，匹配包含tom和jane的所有文档

match_phrase：将tom jane当成一个词组查询，匹配包含“tom jane”的文档

term：不分词，精确查询，下面语句查询不到，需将name改为name.keyword

```
post /users/_doc/_search
{
  "query":{
    "match": {
      "name": "tom jane"
    }
  }
}
```

### 配置文件位置

Elasticsearch具有三个配置文件：

- `elasticsearch.yml` 用于配置Elasticsearch
- `jvm.options` 用于配置Elasticsearch JVM设置
- `log4j2.properties` 用于配置Elasticsearch日志记录



1个索引有多个分片，每个分片有多个副本。

对分片的更新必须同步到副本中。

**数据复制模型：** 分片副本保持同步并从中读取内容的过程。

es的数据复制模型基于 *主备份模型*

> 该模型基于副本组中的一个副本作为主分片。其他副本称为*副本碎片*。主分片充当所有索引操作的主要入口点。它负责验证它们并确保它们是正确的。一旦主分片接受了索引操作，主分片还负责将操作复制到其他副本

主分片遵循以下基本流程：

1. 验证语句结构的正确性，不正确拒绝
2. 在本地执行操作，即索引或删除相关文档。这还将验证字段的内容并在需要时拒绝。
3. 将操作转发到当前同步副本集中的每个副本。如果有多个副本，则这是并行完成的。
4. 一旦所有副本都成功执行了操作并响应了主服务器，主服务器便会向客户端确认请求的成功完成

# 基础

## 1. 和es交互

### Java API

如果你正在使用 Java，在代码中你可以使用 Elasticsearch 内置的两个客户端：

- **节点客户端（Node client）**

  节点客户端作为一个非数据节点加入到本地集群中。换句话说，它本身不保存任何数据，但是它知道数据在集群中的哪个节点中，并且可以把请求转发到正确的节点。

- **传输客户端（Transport client）**

  轻量级的传输客户端可以将请求发送到远程集群。它本身不加入集群，但是它可以将请求转发到集群中的一个节点上。

两个 Java 客户端都是通过 *9300* 端口并使用 Elasticsearch 的原生 *传输* 协议和集群交互。集群中的节点通过端口 9300 彼此通信。如果这个端口没有打开，节点将无法形成一个集群。

Java 客户端作为节点必须和 Elasticsearch 有相同的 *主要* 版本；否则，它们之间将无法互相理解。

### RESTful API with JSON over HTTP

所有其他语言可以使用 RESTful API 通过端口 *9200* 和 Elasticsearch 进行通信，你可以用你最喜爱的 web 客户端访问 Elasticsearch 。事实上，正如你所看到的，你甚至可以使用 `curl` 命令来和 Elasticsearch 交互。

## 2. 面向文档

在应用程序中对象很少只是一个简单的键和值的列表。通常，它们拥有更复杂的数据结构，可能包括日期、地理信息、其他对象或者数组等。

也许有一天你想把这些对象存储在数据库中。使用关系型数据库的行和列存储，这相当于是把一个表现力丰富的对象塞到一个非常大的电子表格中：为了适应表结构，你必须设法将这个对象扁平化—通常一个字段对应一列—而且每次查询时又需要将其重新构造为对象。

Elasticsearch 是 *面向文档* 的，意味着它存储整个对象或 *文档*。Elasticsearch 不仅存储文档，而且 *索引* 每个文档的内容，使之可以被检索。在 Elasticsearch 中，我们对文档进行索引、检索、排序和过滤—而不是对行列数据。这是一种完全不同的思考数据的方式，也是 Elasticsearch 能支持复杂全文检索的原因。

## 3. 集群

ElasticSearch 的主旨是**随时可用和按需扩容**。 而扩容可以通过购买性能更强大（ *垂直扩容* ，或 *纵向扩容* ） 或者数量更多的服务器（ *水平扩容* ，或 *横向扩容* ）来实现。

虽然 Elasticsearch 可以获益于更强大的硬件设备，但是垂直扩容是有极限的。 真正的扩容能力是来自于水平扩容—为集群添加更多的节点，并且将负载压力和稳定性分散到这些节点中。

对于大多数的数据库而言，通常需要对应用程序进行非常大的改动，才能利用上横向扩容的新增资源。 与之相反的是，ElastiSearch天生就是 *分布式的* ，它知道如何通过管理多节点来提高扩容性和可用性。 这也意味着你的应用无需关注这个问题

> 当有节点加入集群中或者从集群中移除节点时，集群将会重新平均分布所有的数据

### 3.1 master

**Master仅仅负责维护集群的状态，并不需要涉及到文档级别的变更和搜索等操作**

1. 创建或删除索引
2. 跟踪哪些节点是集群的一部分
3. 决定将哪些分片分配给哪个节点
4. 等集群范围的操作

上面的一些集群信息, 是由Master节点进行维护, 但是 Master也会把节点信息, 同步给其他节点, 但是只有master节点可以修改

作为用户，我们可以将请求发送到 *集群中的任何节点* ，包括主节点。 **每个节点都知道任意文档所处的位置**，并且能够将我们的请求直接**转发**到存储我们所需文档的节点。 无论我们将请求发送到哪个节点，它都能负责从各个包含我们所需文档的节点收集回数据，并将最终结果返回給客户端。 Elasticsearch 对这一切的管理都是透明的

### 3.2 集群健康状态

```sense
GET /_cluster/health

{
   "cluster_name":          "elasticsearch",
   "status":                "green", 
   "timed_out":             false,
   "number_of_nodes":       1,
   "number_of_data_nodes":  1,
   "active_primary_shards": 0,
   "active_shards":         0,
   "relocating_shards":     0,
   "initializing_shards":   0,
   "unassigned_shards":     0
}
```

`status` 字段指示着当前集群在总体上是否工作正常。它的三种颜色含义如下：

- **`green`**

  所有的主分片和副本分片都正常运行。

- **`yellow`**

  所有的主分片都正常运行，但不是所有的副本分片都正常运行。

- **`red`**

  有主分片没能正常运行。

### 3.3 路由文档到一个分片中

> **shard = hash(routing) % number_of_primary_shards**

索引文档时，如何确定保存的分片：

​	`routing`: 默认是文档的id，也可以设置成一个自定义的值

解释了为什么我们要在创建索引的时候就确定好主分片的数量 并且永远不会改变这个数量：因为如果数量变化了，那么所有之前路由的值都会无效，文档也再也找不到了。

所有的文档 API（ `get` 、 `index` 、 `delete` 、 `bulk` 、 `update` 以及 `mget` ）都接受一个叫做 `routing` 的路由参数 ，通过这个参数我们可以自定义文档到分片的映射。一个自定义的路由参数可以用来确保所有相关的文档——例如所有属于同一个用户的文档——都被存储到同一个分片中

### 3.4 主分片和副本分片的交互

![有三个节点和一个索引的集群](D:\myself\springboot-example\文档\typora\images\es15.png)

我们可以发送请求到集群中的任一节点。 每个节点都有能力处理任意请求。 每个节点都知道集群中任一文档位置，所以可以直接将请求转发到需要的节点上。 在下面的例子中，将所有的请求发送到 `Node 1` ，我们将其称为 ***协调节点(coordinating node)*** 

#### 3.4.1 新建和删除文档

![新建、索引和删除单个文档](D:\myself\springboot-example\文档\typora\images\es16.png)

以下是在主副分片和任何副本分片上面 成功新建，索引和删除文档所需要的步骤顺序：

1. 客户端向 `Node 1` 发送新建或者删除请求。
2. 节点使用文档的 `_id` 确定文档属于分片 0 。请求会被转发到 `Node 3`，因为分片 0 的主分片目前被分配在 `Node 3` 上。
3. `Node 3` 在主分片上面执行请求。如果成功了，它将请求并行转发到 `Node 1` 和 `Node 2` 的副本分片上。一旦所有的副本分片都报告成功, `Node 3` 将向协调节点报告成功，协调节点向客户端报告成功。

**consistency** 一致性

​	在试图执行一个_写_操作之前，主分片都会要求 必须要有 *规定数量(quorum)*（或者换种说法，也即必须要有大多数）的分片副本处于活跃可用状态，才会去执行_写_操作(其中分片副本可以是主分片或者副本分片)。这是为了避免在发生网络分区故障（network partition）的时候进行_写_操作，进而导致数据不一致。

 1. one

    只要主分片ok即可执行写操作

 2. all

    主分片和所有副本分片的状态都没问题才可执行写操作

 3. `quorum` 默认

    大多数的分片副本状态没问题就允许执行_写_操作

    ```
    int( (primary + number_of_replicas) / 2 ) + 1
    ```

  >新索引默认有 `1` 个副本分片，这意味着为满足 `规定数量` *应该* 需要两个活动的分片副本。 但是，这些默认的设置会阻止我们在单一节点上做任何事情。为了避免这个问题，要求只有当 `number_of_replicas` 大于1的时候，规定数量才会执行。

**timeout**    

​	如果没有足够的副本分片会发生什么？ Elasticsearch会等待，希望更多的分片出现。默认情况下，它最多等待1分钟。 如果你需要，你可以使用 `timeout` 参数 使它更早终止： `100` 100毫秒，`30s` 是30秒。

#### 3.4.2 查询一个文档

![取回单个文档](D:\myself\springboot-example\文档\typora\images\es17.png)

1、客户端向 `Node 1` 发送获取请求。

2、节点使用文档的 `_id` 来确定文档属于分片 `0` 。分片 `0` 的副本分片存在于所有的三个节点上。 在这种情况下，它将请求转发到 `Node 2` 。

​	  > **在处理读取请求时，协调结点在每次请求的时候都会通过轮询所有的副本分片来达到负载均衡**。

3、`Node 2` 将文档返回给 `Node 1` ，然后将文档返回给客户端。

在文档被检索时，已经被索引的文档可能已经存在于主分片上但是还没有复制到副本分片。 在这种情况下，副本分片可能会报告文档不存在，但是主分片可能成功返回文档。 一旦索引请求成功返回给用户，文档在主分片和副本分片都是可用的

#### 3.4.3 局部更新文档

![局部更新文档](D:\myself\springboot-example\文档\typora\images\es18.png)

1. 客户端向 `Node 1` 发送更新请求。

2. 它将请求转发到主分片所在的 `Node 3` 。

3. `Node 3` 从主分片检索文档，修改 `_source` 字段中的 JSON ，并且尝试重新索引主分片的文档。 如果文档已经被另一个进程修改，它会重试步骤 3 ，超过 `retry_on_conflict` 次后放弃。

4. 如果 `Node 3` 成功地更新文档，它将新版本的文档并行转发到 `Node 1` 和 `Node 2` 上的副本分片，重新建立索引。 一旦所有副本分片都返回成功， `Node 3` 向协调节点也返回成功，协调节点向客户端返回成功

   <hr/>

   **基于文档的复制**

   当主分片把更改转发到副本分片时， 它不会转发更新请求。 相反，它转发完整文档的新版本。请记住，这些更改将会异步转发到副本分片，并且不能保证它们以发送它们相同的顺序到达。 如果Elasticsearch仅转发更改请求，则可能以错误的顺序应用更改，导致得到损坏的文档。

   <hr/>



## 4. 索引

必须小写，不能以下划线开头，不能包含逗号

### 4.1 动名词解释

**索引（名词）：**

​    是一个存储文档的逻辑概念。 *索引* (*index*) 的复数词为 *indices* 或 *indexes* 。

**索引（动词）：**

​    索引一个文档* 就是存储一个文档到一个 *索引* （名词）中以便被检索和查询。这非常类似于 SQL 语句中的 `INSERT` 关键词，除了文档已存在时，新文档会替换旧文档情况之外。

### 4.2 索引与分片

> 索引实际上是指向一个或者多个物理 *分片* 的 *逻辑命名空间*

> Elasticsearch 是利用分片将数据分发到集群内各处的。分片是数据的容器，文档保存在分片内，分片又被分配到集群内的各个节点里。
>
>  **当你的集群规模扩大或者缩小时， Elasticsearch 会自动的在各节点中迁移分片，使得数据仍然均匀分布在集群里**

分片：

 1. 主分片

 2. 副本分片

    一个副本分片只是一个主分片的拷贝。副本分片作为硬件故障时保护数据不丢失的冗余备份，

    并为搜索和返回文档等**读操作**提供服务，索引操作必须是主分片完成

  **在索引建立的时候就已经确定了主分片数，但是副本分片数可以随时修改**。

### 4.3 故障转移

当集群中只有一个节点在运行时，意味着会有一个单点故障问题——没有冗余。 幸运的是，我们只需再启动一个节点即可防止数据丢失

![æ¥æä¸¤ä¸ªèç¹çéç¾¤](D:\myself\springboot-example\文档\typora\images\es13.png)

如果Master故障，集群状态首先变red，然后选取新的主节点，重新分配副本，选取主分片，集群状态变成yellow（此时有副本故障），

red -> yellow提升是瞬间发生的。

### 4.4 水平扩容

> 分片是一个功能完整的搜索引擎，它拥有使用一个节点上的所有资源的能力。

如上图所示：2个节点，3个分片，每个分片一个副本，再次增加一个节点，

​                                                                           **将参数** `number_of_replicas` **调大到 2**

![æ¥æ2ä»½å¯æ¬åç3ä¸ªèç¹çéç¾¤](D:\myself\springboot-example\文档\typora\images\es14.png)

 此时搜索性能提高了1/3，

索引现在拥有9个分片：3个主分片和6个副本分片。 这意味着我们可以将集群扩容到9个节点，每个节点只有一个分片。相比原来3个节点时，集群搜索性能可以提升 *3* 倍。


当然，如果只是在相同节点数目的集群上增加更多的副本分片并不能提高性能，因为每个分片从节点上获得的资源会变少。 你需要增加更多的硬件资源来提升吞吐量。

但是更多的副本分片数提高了数据冗余量：按照上面的节点配置，我们可以在失去2个节点的情况下不丢失任何数据。

## 5. 文档

### 5.1 更新文档

 文档是 *不可改变* 的，不能修改它们。相反，如果想要更新现有的文档，需要 *重建索引* 或者进行替换

​        Elasticsearch 已将旧文档标记为已删除，并增加一个全新的文档。

​		**旧文档并不会马上消失，当继续索引更多的数据，Elasticsearch 会在后台清理这些已删除文档**

​	1. 从旧文档构建 JSON

     		2. 更改该 JSON
     		3. 删除旧文档
     		4. 索引一个新文档

  **更新整个文档**

​	检索并修改它，然后重新索引整个文档

  **部分更新**

​	然而在内部， `update` API 简单使用与之前描述相同的 *检索-修改-重建索引* 的处理过程。 
​    区别在于这个过程发生在分片内部，这样就避免了多次请求的网络开销。
​    通过减少检索和重建索引步骤之间的时间，我们也减少了其他进程的变更带来冲突的可能性。

**冲突**

​	`update` API 在 *检索* 步骤时检索得到文档当前的 `_version` 号，并传递版本号到 *重建索引* 步骤的 `index` 请求。 如果另一个进程修改了处于检索和重新索引步骤之间的文档，那么 `_version` 号将不匹配，更新请求将会失败。

`retry_on_conflict` 返回失败结果前的重试次数

```sense
POST /website/pageviews/1/_update?retry_on_conflict=5 
{
   "script" : "ctx._source.views+=1",
   "upsert": {
       "views": 0
   }
}
```

### 5.2 删除文档

即使文档不存在（ `Found` 是 `false` ）， `_version` 值仍然会增加。这是 Elasticsearch 内部记录本的一部分，用来确保这些改变在跨多节点时以正确的顺序执行

正如已经在[更新文档]中提到的，删除文档不会立即将文档从磁盘中删除，只是将文档标记为已删除状态。随着你不断的索引更多的数据，Elasticsearch 将会在后台清理标记为已删除的文档。

### 5.3 文档冲突与乐观锁

`_version`

 如果该版本不是当前版本号，我们的请求将会失败

**通过外部系统使用版本控制**

​	指定的外部版本号 >= 当前版本号

​	`version_type=external`

```sense
PUT /website/blog/2?version=5&version_type=external
{
  "title": "My first external blog entry",
  "text":  "Starting to get the hang of this..."
}
```

## 6. 批量操作 _bulk

除了delete没有请求体

每个子请求都是独立执行，因此某个子请求的失败不会对其他子请求的成功与否造成影响。 如果其中任何子请求失败，最顶层的 error 标志被设置为 true ，并且在相应的请求报告出错误明细

这也意味着 `bulk` 请求不是原子的： 不能用它来实现事务控制。每个请求是单独处理的，因此一个请求的成功或失败不会影响其他的请求。

```json
POST /_bulk
{ "delete": { "_index": "website", "_type": "blog", "_id": "123" }}   # 1.要有换行符
{ "create": { "_index": "website", "_type": "blog", "_id": "123" }}
{ "title":    "My first blog post" }
{ "index":  { "_index": "website", "_type": "blog" }}
{ "title":    "My second blog post" }
{ "update": { "_index": "website", "_type": "blog", "_id": "123", "_retry_on_conflict" : 3} }
{ "doc" : {"title" : "My updated blog post"} } # 2.最后一行也要有换行符
```

 **批量操作建议大小**

> 1000-5000个文档并且占用内存5-15M

# document api

## 1. 索引API

```console
PUT _cluster/settings
{
    "persistent": {
        "action.auto_create_index": "twitter,index10,-index1*,+ind*" 
    }
}

PUT _cluster/settings
{
    "persistent": {
        "action.auto_create_index": "false" 
    }
}

PUT _cluster/settings
{
    "persistent": {
        "action.auto_create_index": "true" 
    }
}
```

`write.wait_for_active_shards`: 索引请求返回前需要等待多少个分片写入成功，默认是1，只要主分片写入成功就返回

`index.refresh_interval`  索引数据提交到刷新成新段的间隔，默认是一秒

`refresh`

- false  每一秒刷新一次即最长需要等待一秒才可见，其实是一秒生成了一个新段，这是默认值，这样做的目的是避免生成过多的段，增加合并的成本，这个是异步方式
- true 写入请求同时刷新数据到新段，刷新是请求执行的一部分，所以只要请求返回数据立即可见，会增加CPU开销，这个可以实现同步写入
- wait_for 这种方式可以理解为折衷的方式，写入请求阻塞到数据刷新动作的发生，写入请求最长需等待一秒，这个也实现了同步写入

## 2. get api

**实时性**

​	get API默认是实时的，不受索引刷新率的影响（当数据对搜索可见时）。如果文档已更新但尚未刷新，get API将就地发出刷新调用以使文档可见。自上次刷新以来，这还将使其他文档发生更改。

```console
禁用 realtime: false
```

**source filter**

```
GET twitter/_doc/0?_source=false
GET twitter/_doc/0?_source_includes=*.id&_source_excludes=entities
GET twitter/_doc/0?_source=*.id,retweeted
```

**分散式**

​	get操作将散列到特定的分片中。然后将其重定向到该分片的副本之一，并返回结果。这意味着我们拥有的副本越多，我们将拥有越好的GET缩放比例。

​    `preference`

​             _local： 如果可能，该操作将首选在本地分配的分片上执行 

​             Custom(string) value : 确保相同的副本处理相同的自定义值       

在内部，Elasticsearch将旧文档标记为已删除，并添加了一个全新的文档。旧版本的文档不会立即消失，尽管您将无法访问它。当您继续索引更多数据时，Elasticsearch会在后台清理已删除的文档。

## 3. delete api

**乐观并发控制**

删除操作可以是有条件的，并且只有在对文档的最后修改被分配了由`if_seq_no`和`if_primary_term`参数指定的序号和主要术语的情况下才能执行。如果检测到不匹配，则该操作将产生`VersionConflictException` 和状态码409。有关更多详细信息，请参见[*乐观并发控制*](https://www.elastic.co/guide/en/elasticsearch/reference/7.0/optimistic-concurrency-control.html)。

**版本控制**

索引的每个文档都经过版本控制。删除文档时，`version`可以指定，以确保我们要删除的相关文档实际上已被删除，同时它也没有更改。在文档上执行的每个写操作（包括删除操作）都会导致其版本增加。删除后的文档版本号在短时间内仍然可用，以便控制并发操作。删除的文档版本保持可用状态的时间长度由`index.gc_deletes`索引设置确定，默认为60秒

**超时**

当执行删除操作时，分配给执行删除操作的主分片可能不可用。造成这种情况的某些原因可能是主分片当前正在从存储中恢复或正在进行重定位。默认情况下，删除操作将等待主碎片最多可用1分钟，然后失败并响应错误。该`timeout`参数可用于显式指定其等待时间。这是将其设置为5分钟的示例：

```console
DELETE /twitter/_doc/1?timeout=5m
```

## 4. delete by query

在`_delete_by_query`执行期间，顺序执行多个搜索请求，以找到所有要删除的匹配文档。每次找到一批文档时，都会执行相应的批量请求以删除所有这些文档。如果搜索或批量请求被拒绝，则`_delete_by_query` 依靠默认策略重试被拒绝的请求（最多10次，并以指数方式退回）。达到最大重试次数限制将导致`_delete_by_query` 中止，并且所有失败都将在`failures`的响应中返回。已经执行的删除仍然会保留。换句话说，该过程不会回滚，只会中止。当第一个失败导致中止时，失败的批量请求返回的所有失败都将在`failures` 元素; 因此，可能会有很多失败的实体

如果您想计算版本冲突而不是使它们中止，请`conflicts=proceed`在url或`"conflicts": "proceed"`请求正文中进行设置

```console
POST twitter/_delete_by_query?conflicts=proceed
{
  "query": {
    "match_all": {}
  }
}
```

默认情况下，`_delete_by_query`使用滚动批处理1000。您可以使用`scroll_size`URL参数更改批处理大小

```console
POST twitter/_delete_by_query?scroll_size=5000
{
  "query": {
    "term": {
      "user": "kimchy"
    }
  }
}
```

