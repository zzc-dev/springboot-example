https://www.elastic.co/guide/cn/elasticsearch/guide/current/_an-empty-cluster.html  es2.x官方中文文档

1. es可以从集群中的任何节点获取数据

2. 批量索引文档，减少网络IO。最佳批处理大小取决于：文档大小和复杂性、集群资源的可用性。
   建议：1000-5000个文档，有效负载5M-10M

3. es的分片故障处理：主分片所在节点故障如何处理

4. es的节点分类

   



响应体：

- `took` – Elasticsearch运行查询多长时间（以毫秒为单位）
- `timed_out` –搜索请求是否超时
- `_shards` –搜索了多少个分片，以及成功，失败或跳过了多少个分片。
- `max_score` –找到的最相关文件的分数
- `hits.total.value` -找到了多少个匹配的文档
- `hits.sort` -文档的排序位置（不按相关性得分排序时）
- `hits._score`-文档的相关性得分（使用时不适用`match_all`）



match：分词查询，匹配包含tom和jane的所有文档

match_phrase：将tom jane当成一个词组查询，匹配包含“tom jane”的文档

term：不分词，精确查询，下面语句查询不到，需将name改为name.keyword

```
post /users/_doc/_search
{
  "query":{
    "match": {
      "name": "tom jane"
    }
  }
}
```

### 配置文件位置

Elasticsearch具有三个配置文件：

- `elasticsearch.yml` 用于配置Elasticsearch
- `jvm.options` 用于配置Elasticsearch JVM设置
- `log4j2.properties` 用于配置Elasticsearch日志记录



1个索引有多个分片，每个分片有多个副本。

对分片的更新必须同步到副本中。

**数据复制模型：** 分片副本保持同步并从中读取内容的过程。

es的数据复制模型基于 *主备份模型*

> 该模型基于副本组中的一个副本作为主分片。其他副本称为*副本碎片*。主分片充当所有索引操作的主要入口点。它负责验证它们并确保它们是正确的。一旦主分片接受了索引操作，主分片还负责将操作复制到其他副本

主分片遵循以下基本流程：

1. 验证语句结构的正确性，不正确拒绝
2. 在本地执行操作，即索引或删除相关文档。这还将验证字段的内容并在需要时拒绝。
3. 将操作转发到当前同步副本集中的每个副本。如果有多个副本，则这是并行完成的。
4. 一旦所有副本都成功执行了操作并响应了主服务器，主服务器便会向客户端确认请求的成功完成

# 基础

## 1. 和es交互

### Java API

如果你正在使用 Java，在代码中你可以使用 Elasticsearch 内置的两个客户端：

- **节点客户端（Node client）**

  节点客户端作为一个非数据节点加入到本地集群中。换句话说，它本身不保存任何数据，但是它知道数据在集群中的哪个节点中，并且可以把请求转发到正确的节点。

- **传输客户端（Transport client）**

  轻量级的传输客户端可以将请求发送到远程集群。它本身不加入集群，但是它可以将请求转发到集群中的一个节点上。

两个 Java 客户端都是通过 *9300* 端口并使用 Elasticsearch 的原生 *传输* 协议和集群交互。集群中的节点通过端口 9300 彼此通信。如果这个端口没有打开，节点将无法形成一个集群。

Java 客户端作为节点必须和 Elasticsearch 有相同的 *主要* 版本；否则，它们之间将无法互相理解。

### RESTful API with JSON over HTTP

所有其他语言可以使用 RESTful API 通过端口 *9200* 和 Elasticsearch 进行通信，你可以用你最喜爱的 web 客户端访问 Elasticsearch 。事实上，正如你所看到的，你甚至可以使用 `curl` 命令来和 Elasticsearch 交互。

## 2. 面向文档

在应用程序中对象很少只是一个简单的键和值的列表。通常，它们拥有更复杂的数据结构，可能包括日期、地理信息、其他对象或者数组等。

也许有一天你想把这些对象存储在数据库中。使用关系型数据库的行和列存储，这相当于是把一个表现力丰富的对象塞到一个非常大的电子表格中：为了适应表结构，你必须设法将这个对象扁平化—通常一个字段对应一列—而且每次查询时又需要将其重新构造为对象。

Elasticsearch 是 *面向文档* 的，意味着它存储整个对象或 *文档*。Elasticsearch 不仅存储文档，而且 *索引* 每个文档的内容，使之可以被检索。在 Elasticsearch 中，我们对文档进行索引、检索、排序和过滤—而不是对行列数据。这是一种完全不同的思考数据的方式，也是 Elasticsearch 能支持复杂全文检索的原因。

## 3. 集群

ElasticSearch 的主旨是**随时可用和按需扩容**。 而扩容可以通过购买性能更强大（ *垂直扩容* ，或 *纵向扩容* ） 或者数量更多的服务器（ *水平扩容* ，或 *横向扩容* ）来实现。

虽然 Elasticsearch 可以获益于更强大的硬件设备，但是垂直扩容是有极限的。 真正的扩容能力是来自于水平扩容—为集群添加更多的节点，并且将负载压力和稳定性分散到这些节点中。

对于大多数的数据库而言，通常需要对应用程序进行非常大的改动，才能利用上横向扩容的新增资源。 与之相反的是，ElastiSearch天生就是 *分布式的* ，它知道如何通过管理多节点来提高扩容性和可用性。 这也意味着你的应用无需关注这个问题

> 当有节点加入集群中或者从集群中移除节点时，集群将会重新平均分布所有的数据

### 3.1 master

**Master仅仅负责维护集群的状态，并不需要涉及到文档级别的变更和搜索等操作**

1. 创建或删除索引
2. 跟踪哪些节点是集群的一部分
3. 决定将哪些分片分配给哪个节点
4. 等集群范围的操作

上面的一些集群信息, 是由Master节点进行维护, 但是 Master也会把节点信息, 同步给其他节点, 但是只有master节点可以修改

作为用户，我们可以将请求发送到 *集群中的任何节点* ，包括主节点。 **每个节点都知道任意文档所处的位置**，并且能够将我们的请求直接**转发**到存储我们所需文档的节点。 无论我们将请求发送到哪个节点，它都能负责从各个包含我们所需文档的节点收集回数据，并将最终结果返回給客户端。 Elasticsearch 对这一切的管理都是透明的

### 3.2 集群健康状态

```sense
GET /_cluster/health

{
   "cluster_name":          "elasticsearch",
   "status":                "green", 
   "timed_out":             false,
   "number_of_nodes":       1,
   "number_of_data_nodes":  1,
   "active_primary_shards": 0,
   "active_shards":         0,
   "relocating_shards":     0,
   "initializing_shards":   0,
   "unassigned_shards":     0
}
```

`status` 字段指示着当前集群在总体上是否工作正常。它的三种颜色含义如下：

- **`green`**

  所有的主分片和副本分片都正常运行。

- **`yellow`**

  所有的主分片都正常运行，但不是所有的副本分片都正常运行。

- **`red`**

  有主分片没能正常运行。

## 4. 索引

必须小写，不能以下划线开头，不能包含逗号

### 4.1 动名词解释

**索引（名词）：**

​    是一个存储文档的逻辑概念。 *索引* (*index*) 的复数词为 *indices* 或 *indexes* 。

**索引（动词）：**

​    索引一个文档* 就是存储一个文档到一个 *索引* （名词）中以便被检索和查询。这非常类似于 SQL 语句中的 `INSERT` 关键词，除了文档已存在时，新文档会替换旧文档情况之外。

### 4.2 索引与分片

> 索引实际上是指向一个或者多个物理 *分片* 的 *逻辑命名空间*

> Elasticsearch 是利用分片将数据分发到集群内各处的。分片是数据的容器，文档保存在分片内，分片又被分配到集群内的各个节点里。
>
>  **当你的集群规模扩大或者缩小时， Elasticsearch 会自动的在各节点中迁移分片，使得数据仍然均匀分布在集群里**

分片：

 1. 主分片

 2. 副本分片

    一个副本分片只是一个主分片的拷贝。副本分片作为硬件故障时保护数据不丢失的冗余备份，

    并为搜索和返回文档等**读操作**提供服务，索引操作必须是主分片完成

  **在索引建立的时候就已经确定了主分片数，但是副本分片数可以随时修改**。

### 4.3 故障转移

当集群中只有一个节点在运行时，意味着会有一个单点故障问题——没有冗余。 幸运的是，我们只需再启动一个节点即可防止数据丢失

![æ¥æä¸¤ä¸ªèç¹çéç¾¤](D:\myself\springboot-example\文档\typora\images\es13.png)

如果Master故障，集群状态首先变red，然后选取新的主节点，重新分配副本，选取主分片，集群状态变成yellow（此时有副本故障），

red -> yellow提升是瞬间发生的。

### 4.4 水平扩容

> 分片是一个功能完整的搜索引擎，它拥有使用一个节点上的所有资源的能力。

如上图所示：2个节点，3个分片，每个分片一个副本，再次增加一个节点，

​                                                                           **将参数** `number_of_replicas` **调大到 2**

![æ¥æ2ä»½å¯æ¬åç3ä¸ªèç¹çéç¾¤](D:\myself\springboot-example\文档\typora\images\es14.png)

 此时搜索性能提高了1/3，

索引现在拥有9个分片：3个主分片和6个副本分片。 这意味着我们可以将集群扩容到9个节点，每个节点只有一个分片。相比原来3个节点时，集群搜索性能可以提升 *3* 倍。


当然，如果只是在相同节点数目的集群上增加更多的副本分片并不能提高性能，因为每个分片从节点上获得的资源会变少。 你需要增加更多的硬件资源来提升吞吐量。

但是更多的副本分片数提高了数据冗余量：按照上面的节点配置，我们可以在失去2个节点的情况下不丢失任何数据。

## 5. 文档

### 5.1 更新文档

 文档是 *不可改变* 的，不能修改它们。相反，如果想要更新现有的文档，需要 *重建索引* 或者进行替换

​        Elasticsearch 已将旧文档标记为已删除，并增加一个全新的文档。

​		**旧文档并不会马上消失，当继续索引更多的数据，Elasticsearch 会在后台清理这些已删除文档**

		1. 从旧文档构建 JSON
  		2. 更改该 JSON
  		3. 删除旧文档
  		4. 索引一个新文档

### 5.2 删除文档

即使文档不存在（ `Found` 是 `false` ）， `_version` 值仍然会增加。这是 Elasticsearch 内部记录本的一部分，用来确保这些改变在跨多节点时以正确的顺序执行

正如已经在[更新文档]中提到的，删除文档不会立即将文档从磁盘中删除，只是将文档标记为已删除状态。随着你不断的索引更多的数据，Elasticsearch 将会在后台清理标记为已删除的文档。

# document api

## 1. 索引API

```console
PUT _cluster/settings
{
    "persistent": {
        "action.auto_create_index": "twitter,index10,-index1*,+ind*" 
    }
}

PUT _cluster/settings
{
    "persistent": {
        "action.auto_create_index": "false" 
    }
}

PUT _cluster/settings
{
    "persistent": {
        "action.auto_create_index": "true" 
    }
}
```

`write.wait_for_active_shards`: 索引请求返回前需要等待多少个分片写入成功，默认是1，只要主分片写入成功就返回

`index.refresh_interval`  索引数据提交到刷新成新段的间隔，默认是一秒

`refresh`

- false  每一秒刷新一次即最长需要等待一秒才可见，其实是一秒生成了一个新段，这是默认值，这样做的目的是避免生成过多的段，增加合并的成本，这个是异步方式
- true 写入请求同时刷新数据到新段，刷新是请求执行的一部分，所以只要请求返回数据立即可见，会增加CPU开销，这个可以实现同步写入
- wait_for 这种方式可以理解为折衷的方式，写入请求阻塞到数据刷新动作的发生，写入请求最长需等待一秒，这个也实现了同步写入

## 2. get api

**实时性**

​	get API默认是实时的，不受索引刷新率的影响（当数据对搜索可见时）。如果文档已更新但尚未刷新，get API将就地发出刷新调用以使文档可见。自上次刷新以来，这还将使其他文档发生更改。

```console
禁用 realtime: false
```

**source filter**

```
GET twitter/_doc/0?_source=false
GET twitter/_doc/0?_source_includes=*.id&_source_excludes=entities
GET twitter/_doc/0?_source=*.id,retweeted
```

**分散式**

​	get操作将散列到特定的分片中。然后将其重定向到该分片的副本之一，并返回结果。这意味着我们拥有的副本越多，我们将拥有越好的GET缩放比例。

​    `preference`

​             _local： 如果可能，该操作将首选在本地分配的分片上执行 

​             Custom(string) value : 确保相同的副本处理相同的自定义值       

在内部，Elasticsearch将旧文档标记为已删除，并添加了一个全新的文档。旧版本的文档不会立即消失，尽管您将无法访问它。当您继续索引更多数据时，Elasticsearch会在后台清理已删除的文档。

## 3. delete api

**乐观并发控制**

删除操作可以是有条件的，并且只有在对文档的最后修改被分配了由`if_seq_no`和`if_primary_term`参数指定的序号和主要术语的情况下才能执行。如果检测到不匹配，则该操作将产生`VersionConflictException` 和状态码409。有关更多详细信息，请参见[*乐观并发控制*](https://www.elastic.co/guide/en/elasticsearch/reference/7.0/optimistic-concurrency-control.html)。

**版本控制**

索引的每个文档都经过版本控制。删除文档时，`version`可以指定，以确保我们要删除的相关文档实际上已被删除，同时它也没有更改。在文档上执行的每个写操作（包括删除操作）都会导致其版本增加。删除后的文档版本号在短时间内仍然可用，以便控制并发操作。删除的文档版本保持可用状态的时间长度由`index.gc_deletes`索引设置确定，默认为60秒

**超时**

当执行删除操作时，分配给执行删除操作的主分片可能不可用。造成这种情况的某些原因可能是主分片当前正在从存储中恢复或正在进行重定位。默认情况下，删除操作将等待主碎片最多可用1分钟，然后失败并响应错误。该`timeout`参数可用于显式指定其等待时间。这是将其设置为5分钟的示例：

```console
DELETE /twitter/_doc/1?timeout=5m
```

## 4. delete by query

在`_delete_by_query`执行期间，顺序执行多个搜索请求，以找到所有要删除的匹配文档。每次找到一批文档时，都会执行相应的批量请求以删除所有这些文档。如果搜索或批量请求被拒绝，则`_delete_by_query` 依靠默认策略重试被拒绝的请求（最多10次，并以指数方式退回）。达到最大重试次数限制将导致`_delete_by_query` 中止，并且所有失败都将在`failures`的响应中返回。已经执行的删除仍然会保留。换句话说，该过程不会回滚，只会中止。当第一个失败导致中止时，失败的批量请求返回的所有失败都将在`failures` 元素; 因此，可能会有很多失败的实体

如果您想计算版本冲突而不是使它们中止，请`conflicts=proceed`在url或`"conflicts": "proceed"`请求正文中进行设置

```console
POST twitter/_delete_by_query?conflicts=proceed
{
  "query": {
    "match_all": {}
  }
}
```

默认情况下，`_delete_by_query`使用滚动批处理1000。您可以使用`scroll_size`URL参数更改批处理大小

```console
POST twitter/_delete_by_query?scroll_size=5000
{
  "query": {
    "term": {
      "user": "kimchy"
    }
  }
}
```

