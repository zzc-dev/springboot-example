# 一、kafka集群搭建

hadoop102      hadoop103          hadoop104

zk                               zk                    zk

kafka                     kafka                 kafka

http://kafka.apache.org/downloads.html

**部署：**

![image-20210201210654968](D:\myself\springboot-example\文档\typora\images\kafka01.png)

![image-20210201210733879](D:\myself\springboot-example\文档\typora\images\kafka02.png)

​                               [atguigu@hadoop102 module]$ xsync kafka/
​                                注意：分发之后记得配置其他机器的环境变量

​								7）分别在hadoop103和hadoop104上修改配置文件/opt/module/kafka/config/server.properties 中的broker.id=1、broker.id=2
​										注：broker.id不得重复

![image-20210201210906174](D:\myself\springboot-example\文档\typora\images\kafka03.png)

# 二、命令行操作

## 2.1 topic

1）查看当前服务器中的所有topic

```
[atguigu@hadoop102 kafka]$ bin/kafka-topics.sh --zookeeper hadoop102:2181 --list
```

2）创建topic

​		replication-factor: 副本数，包含leader和follower
​        partitions: 分区数

```
[atguigu@hadoop102 kafka]$ bin/kafka-topics.sh --zookeeper hadoop102:2181 --create --replication-factor 3 --partitions 1 --topic first
```

3）删除topic

```
[atguigu@hadoop102 kafka]$ bin/kafka-topics.sh --zookeeper hadoop102:2181 --delete --topic first
需要server.properties中设置delete.topic.enable=true否则只是标记删除。
```

4）发送消息

```
[atguigu@hadoop102 kafka]$ bin/kafka-console-producer.sh --broker-list hadoop102:9092 --topic first
```

5）消费消息
	-from-beginning：会把主题中以往所有的数据都读取出来。

```
[atguigu@hadoop102 kafka]$ bin/kafka-console-consumer.sh \ --bootstrap-server hadoop102:9092 --topic first
[atguigu@hadoop102 kafka]$ bin/kafka-console-consumer.sh \ --bootstrap-server hadoop102:9092 --from-beginning --topic first
```

6）查看某个Topic的详情

```
[atguigu@hadoop102 kafka]$ bin/kafka-topics.sh --zookeeper hadoop102:2181 --describe --topic first
```

7）修改分区数

```
[atguigu@hadoop102 kafka]$ bin/kafka-topics.sh --zookeeper hadoop102:2181 --alter --topic first --partitions 6
```

