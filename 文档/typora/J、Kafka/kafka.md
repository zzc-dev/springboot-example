# 一、概述

>Kafka是一个**发布式**的基于**发布/订阅**模式的消息队列，主要应用于大数据实时处理领域

Kafka 是linkedin 公司用于日志处理的分布式消息队列，同时支持离线和在线日志处理。kafka 对消息保存时根据Topic进行归类，发送消息者成为Producer,消息接受者成为Consumer,此外kafka 集群有多个kafka 实例组成，每个实例(server)称为broker。无论是kafka集群，还是producer和consumer 都依赖于zookeeper 来保证系统可用性，为集群保存一些meta 信息。

## 1.1 消息队列的两种模式

**1. 点对点模式**

​	一对一，消费者主动拉取数据，消息收到后消息清除
​    消息被消费以后，queue中不再有存储，所以消息消费者不可能消费到已经被消费的消息。Queue支持存在多个消费者，但是对一个消息而言，只会有一个消费者可以消费

**2. 发布订阅模式**

  一对多，并且有两种消费模式，一是队列主动推送，二是消费者基于长连接轮询主动拉取数据，kafka属于后者



解耦，消峰，解决生产者速度>消费者速度的问题

## 1.2 kafka 文件存储机制

![image-20210201211711400](D:\myself\springboot-example\文档\typora\images\kafka04.png)

kafka中消息是以topic进行分类的，生产者生产消息，消费组消费消息，都是面向topic的

topic是逻辑概念，而partition是物理概念，每个partition对应一个log文件，该log文件存储生产者生产的数据，不断追加到该文件的尾端，且每条数据都有自己的offset。消费者组中的每个消费者，都会实时记录自身的offset，以便出错恢复时，从上次的位置继续消费。

![image-20210201212211947](D:\myself\springboot-example\文档\typora\images\kafka05.png)

每个分区目录下都有.index和.log文件，每个log文件存储的大小可配置，默认1G。分区采用分段机制存储，当超过1G时，再次创建一个log文件，文件名为自身最小的offset，当消费组消费消息时，首先根据自身的offset找到index对应的log文件偏移量，根据文件偏移量采用**二分查找**找到对应的log文件。

## 1.3 分区

   消费者默认50个分区consumer-offset-n

### 1.3.1 分区原因：

	1. 方便在集群中扩展。每个分区可以通过调整以适应所在机器的存储大小，处理速度，而一个topic是由多个partition组成，这样整个集群就可以适应任意大小的数据了
 	2. 提高并发度。

### 1.3.2 分区策略

